@book{Descartes2006,
	address = {Oxford},
	author = {Descartes, Ren{\'{e}}},
	editor = {Maclean, Ian},
	isbn = {0199540071},
	publisher = {Oxford University Press},
	shorttitle = {A Discourse on the Method},
	title = {{A Discourse on the Method of Correctly Conducting One's Reason and Seeking Trugh in the Sciences}},
	translator = {Maclean, Ian},
	year = {2006}
}

@article{Banerjee2015,
	author = {Banerjee, a. and Duflo, E. and Goldberg, N. and Karlan, D. and Osei, R. and Pariente, W. and Shapiro, J. and Thuysbaert, B. and Udry, C.},
	doi = {10.1126/science.1260799},
	issn = {0036-8075},
	journal = {Science},
	number = {6236},
	pages = {1260799--1260799},
	title = {{A multifaceted program causes lasting progress for the very poor: Evidence from six countries}},
	url = {http://www.sciencemag.org/cgi/doi/10.1126/science.1260799},
	volume = {348},
	year = {2015}
}

@incollection{Griffiths2008a,
	abstract = {Categorization as nonparametric Bayesian density estimation Griffiths, Thomas L., Sanborn, Adam N., Canini, Kevin R. and Navarro, Daniel J. (2008) Categorization as nonparametric Bayesian density estimation. In: The probabilistic mind : prospects for Bayesian cognitive science. Oxford University Press, Oxford , pp. 303-328. ISBN 9780199216093},
	author = {Griffiths, Thomas L and Sanborn, Adam N and Canini, Kevin R and Navarro, Daniel J},
	booktitle = {The probabilistic mind Prospects for Bayesian cognitive science},
	editor = {Chater, Nick and Oaksford, Mike},
	isbn = {9780199216093},
	keywords = {Bayesian models},
	pages = {303--328},
	publisher = {Oxford University Press},
	title = {{Categorization as nonparametric Bayesian density estimation}},
	url = {http://books.google.com/books?hl=en{\&}lr={\&}id=rQ-iMw6tNgsC{\&}oi=fnd{\&}pg=PA303{\&}dq=Categorization+as+nonparametric+Bayesian+density+estimation{\&}ots=0JU34Glks0{\&}sig=yIhJDMAl8r93yYyS2qn6eLqjs3A},
	year = {2008}
}

@article{Lazaridou2016,
	abstract = {We propose an interactive multimodal framework for language learning. Instead of being passively exposed to large amounts of natural text, our learners (implemented as feed-forward neural networks) engage in cooperative referential games starting from a tabula rasa setup, and thus develop their own language from the need to communicate in order to succeed at the game. Preliminary experiments provide promising results, but also suggest that it is important to ensure that agents trained in this way do not develop an adhoc communication code only effective for the game they are playing},
	archivePrefix = {arXiv},
	arxivId = {1605.07133},
	author = {Lazaridou, Angeliki and Pham, Nghia The and Baroni, Marco},
	eprint = {1605.07133},
	journal = {arXiv},
	title = {{Towards Multi-Agent Communication-Based Language Learning}},
	url = {http://arxiv.org/abs/1605.07133},
	year = {2016}
}

